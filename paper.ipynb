{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Symbol                                      Security Name Market Category  \\\n0   AACG  ATA Creativity Global - American Depositary Sh...               G   \n1   AACQ     Artius Acquisition Inc. - Class A Common Stock               S   \n2  AACQU  Artius Acquisition Inc. - Unit consisting of o...               S   \n3  AACQW                  Artius Acquisition Inc. - Warrant               S   \n4    AAL       American Airlines Group, Inc. - Common Stock               Q   \n\n  Test Issue Financial Status  Round Lot Size ETF NextShares  \n0          N                N             100   N          N  \n1          N                N             100   N          N  \n2          N                N             100   N          N  \n3          N                N             100   N          N  \n4          N                N             100   N          N  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbol</th>\n      <th>Security Name</th>\n      <th>Market Category</th>\n      <th>Test Issue</th>\n      <th>Financial Status</th>\n      <th>Round Lot Size</th>\n      <th>ETF</th>\n      <th>NextShares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AACG</td>\n      <td>ATA Creativity Global - American Depositary Sh...</td>\n      <td>G</td>\n      <td>N</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AACQ</td>\n      <td>Artius Acquisition Inc. - Class A Common Stock</td>\n      <td>S</td>\n      <td>N</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AACQU</td>\n      <td>Artius Acquisition Inc. - Unit consisting of o...</td>\n      <td>S</td>\n      <td>N</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AACQW</td>\n      <td>Artius Acquisition Inc. - Warrant</td>\n      <td>S</td>\n      <td>N</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAL</td>\n      <td>American Airlines Group, Inc. - Common Stock</td>\n      <td>Q</td>\n      <td>N</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We downloaded two datasets from the nasdaq ftp, nasdaqListed and otherlisted\n",
    "# here we want to analyze the nasdaq downloaded dataset\n",
    "df_nasdaq_list = pd.read_csv('datainputs/nasdaqlisted.txt', delimiter='|')\n",
    "df_nasdaq_list.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  ACT Symbol                                      Security Name Exchange  \\\n0          A            Agilent Technologies, Inc. Common Stock        N   \n1         AA                    Alcoa Corporation Common Stock         N   \n2        AAA  Listed Funds Trust AAF First Priority CLO Bond...        P   \n3       AAAU             Goldman Sachs Physical Gold ETF Shares        P   \n4      AAC.U  Ares Acquisition Corporation Units, each consi...        N   \n\n  CQS Symbol ETF  Round Lot Size Test Issue NASDAQ Symbol  \n0          A   N             100          N             A  \n1         AA   N             100          N            AA  \n2        AAA   Y             100          N           AAA  \n3       AAAU   Y             100          N          AAAU  \n4      AAC.U   N             100          N          AAC=  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACT Symbol</th>\n      <th>Security Name</th>\n      <th>Exchange</th>\n      <th>CQS Symbol</th>\n      <th>ETF</th>\n      <th>Round Lot Size</th>\n      <th>Test Issue</th>\n      <th>NASDAQ Symbol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Agilent Technologies, Inc. Common Stock</td>\n      <td>N</td>\n      <td>A</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AA</td>\n      <td>Alcoa Corporation Common Stock</td>\n      <td>N</td>\n      <td>AA</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>AA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAA</td>\n      <td>Listed Funds Trust AAF First Priority CLO Bond...</td>\n      <td>P</td>\n      <td>AAA</td>\n      <td>Y</td>\n      <td>100</td>\n      <td>N</td>\n      <td>AAA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAAU</td>\n      <td>Goldman Sachs Physical Gold ETF Shares</td>\n      <td>P</td>\n      <td>AAAU</td>\n      <td>Y</td>\n      <td>100</td>\n      <td>N</td>\n      <td>AAAU</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAC.U</td>\n      <td>Ares Acquisition Corporation Units, each consi...</td>\n      <td>N</td>\n      <td>AAC.U</td>\n      <td>N</td>\n      <td>100</td>\n      <td>N</td>\n      <td>AAC=</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we want to analyze the nasdaq dataset for the other stocks including NYSE\n",
    "df_other_list = pd.read_csv('datainputs/otherlisted.txt', delimiter='|')\n",
    "df_other_list.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For this study we are planning on using just stocks Symbols and Names,\n",
    "# to understand them we are going to print their statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Symbol      Security Name\ncount    4191               4191\nunique   4191               4186\ntop      SYRS  NASDAQ TEST STOCK\nfreq        1                  4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbol</th>\n      <th>Security Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4191</td>\n      <td>4191</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>4191</td>\n      <td>4186</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>SYRS</td>\n      <td>NASDAQ TEST STOCK</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nasdaq_list[['Symbol', 'Security Name']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       ACT Symbol               Security Name\ncount        5706                        5706\nunique       5706                        5686\ntop           PWC  NYSE Test One Common Stock\nfreq            1                           6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACT Symbol</th>\n      <th>Security Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5706</td>\n      <td>5706</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>5706</td>\n      <td>5686</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>PWC</td>\n      <td>NYSE Test One Common Stock</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other_list[['ACT Symbol', 'Security Name']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# As we can see, most stocks are unique on each,\n",
    "# which is a good initial sign that the dataset is probably good\n",
    "# for now we are going to keep them like this and merge into a second dataframe\n",
    "# to be used for lookups in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Symbol               Security Name\ncount    9897                        9897\nunique   9897                        9871\ntop       PWC  NYSE Test One Common Stock\nfreq        1                           6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbol</th>\n      <th>Security Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9897</td>\n      <td>9897</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>9897</td>\n      <td>9871</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>PWC</td>\n      <td>NYSE Test One Common Stock</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we need to rename different columns to match on concat.\n",
    "df_other_list.rename(columns={'ACT Symbol': 'Symbol'}, inplace=True)\n",
    "#Now we can concat these datasets into a single stocks dataframe.\n",
    "stocks = pd.concat([df_nasdaq_list[['Symbol', 'Security Name']],\n",
    "                    df_other_list[['Symbol', 'Security Name']]])\n",
    "stocks.to_csv('datawork/stocks.csv', sep='|')\n",
    "stocks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now we have our initial stock dataset ready.\n",
    "# lets keep this dataset to the side now for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Next step lets get some r/wallStreetBets dataset, import and do some data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First import into a Dataframe\n",
    "df_wsb = pd.read_csv('datainputs/reddit_wsb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title  score      id  \\\n0  It's not about the money, it's about sending a...     55  l6ulcx   \n1  Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n2                                    Exit the system      0  l6uhhn   \n3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n4  Not to distract from GME, just thought our AMC...     71  l6ufgy   \n\n                                                 url  comms_num       created  \\\n0                    https://v.redd.it/6j75regs72e61          6  1.611863e+09   \n1                    https://v.redd.it/ah50lyny62e61         23  1.611862e+09   \n2  https://www.reddit.com/r/wallstreetbets/commen...         47  1.611862e+09   \n3  https://sec.report/Document/0001193125-21-019848/         74  1.611862e+09   \n4                https://i.redd.it/4h2sukb662e61.jpg        156  1.611862e+09   \n\n                                                body            timestamp  \n0                                                NaN  2021-01-28 21:37:41  \n1                                                NaN  2021-01-28 21:32:10  \n2  The CEO of NASDAQ pushed to halt trading “to g...  2021-01-28 21:30:35  \n3                                                NaN  2021-01-28 21:28:57  \n4                                                NaN  2021-01-28 21:26:56  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>id</th>\n      <th>url</th>\n      <th>comms_num</th>\n      <th>created</th>\n      <th>body</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It's not about the money, it's about sending a...</td>\n      <td>55</td>\n      <td>l6ulcx</td>\n      <td>https://v.redd.it/6j75regs72e61</td>\n      <td>6</td>\n      <td>1.611863e+09</td>\n      <td>NaN</td>\n      <td>2021-01-28 21:37:41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Math Professor Scott Steiner says the numbers ...</td>\n      <td>110</td>\n      <td>l6uibd</td>\n      <td>https://v.redd.it/ah50lyny62e61</td>\n      <td>23</td>\n      <td>1.611862e+09</td>\n      <td>NaN</td>\n      <td>2021-01-28 21:32:10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Exit the system</td>\n      <td>0</td>\n      <td>l6uhhn</td>\n      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n      <td>47</td>\n      <td>1.611862e+09</td>\n      <td>The CEO of NASDAQ pushed to halt trading “to g...</td>\n      <td>2021-01-28 21:30:35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n      <td>29</td>\n      <td>l6ugk6</td>\n      <td>https://sec.report/Document/0001193125-21-019848/</td>\n      <td>74</td>\n      <td>1.611862e+09</td>\n      <td>NaN</td>\n      <td>2021-01-28 21:28:57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Not to distract from GME, just thought our AMC...</td>\n      <td>71</td>\n      <td>l6ufgy</td>\n      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n      <td>156</td>\n      <td>1.611862e+09</td>\n      <td>NaN</td>\n      <td>2021-01-28 21:26:56</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see a sneak peek of the data,\n",
    "# as you can see, the dataset has a lot of information,\n",
    "# but for our case we will start exploring on title, body, timestamp and the unique identifier\n",
    "df_wsb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        title   body timestamp     id\n",
      "count   36668  18534     36668  36668\n",
      "unique  35795  18295     27008  36668\n",
      "freq       37     17        14      1\n"
     ]
    }
   ],
   "source": [
    "#Now lets run some basic summary, to check on these attributes\n",
    "print(df_wsb[['title', 'body', 'timestamp','id']].describe()\n",
    "      .loc[['count','unique','freq']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fernak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/fernak/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/fernak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/fernak/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/fernak/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt') #tokenizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(wnl.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 353094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wordlist = []\n",
    "\n",
    "for title in df_wsb['title']:\n",
    "    words = nltk.word_tokenize(lemmatize_sentence(title))\n",
    "    for word in words:\n",
    "        if not word in stop_words:\n",
    "            wordlist.append(word)\n",
    "print(\"size: \" + str(len(wordlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-87925599c3fc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;31m# print(sortFreqDict(wordListToFreqDict(wordlist)))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0mstock_dict_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstocks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m \u001B[0mreturn_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstock_dict_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'GameStop'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m \u001B[0;31m# stock_dict = pd.Series(stocks['Security Name'].values,index=stocks['Symbol']).to_dict()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;31m# wd={}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-17-87925599c3fc>\u001B[0m in \u001B[0;36mreturn_results\u001B[0;34m(list_of_dicts, query, threshold)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist_of_dicts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mratios\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfuzz\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mratio\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m# ensure both are in string\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m \u001B[0;34m\"index\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"score\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mratios\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def return_results(list_of_dicts, query, threshold):\n",
    "    scores = []\n",
    "    for index, item in enumerate(list_of_dicts):\n",
    "        values = list(item.values())\n",
    "        ratios = [fuzz.ratio(str(query), str(value)) for value in values] # ensure both are in string\n",
    "        scores.append({ \"index\": index, \"score\": max(ratios)})\n",
    "\n",
    "    filtered_scores = [item for item in scores if item['score'] >= threshold]\n",
    "    sorted_filtered_scores = sorted(filtered_scores, key = lambda k: k['score'], reverse=True)\n",
    "    filtered_list_of_dicts = [ list_of_dicts[item[\"index\"]] for item in sorted_filtered_scores ]\n",
    "    return filtered_list_of_dicts\n",
    "\n",
    "# def wordListToFreqDict(wordlist):\n",
    "#     wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "#     return dict(list(zip(wordlist,wordfreq)))\n",
    "# #\n",
    "# def sortFreqDict(freqdict):\n",
    "#     aux = [(freqdict[key], key) for key in freqdict]\n",
    "#     aux.sort()\n",
    "#     aux.reverse()\n",
    "#     return aux\n",
    "\n",
    "# print(sortFreqDict(wordListToFreqDict(wordlist)))\n",
    "stock_dict_list = stocks.to_dict()\n",
    "return_results(stock_dict_list,'GameStop',10)\n",
    "# stock_dict = pd.Series(stocks['Security Name'].values,index=stocks['Symbol']).to_dict()\n",
    "# wd={}\n",
    "# for word in wordlist:\n",
    "#     # if stock_dict.get(word):\n",
    "#         if word in wd:\n",
    "#             wd[word] = wd[word]+1\n",
    "#         else:\n",
    "#             wd[word]=1\n",
    "# print(sortFreqDict(wd))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for word in words:\n",
    "# print(df_wsb['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Update the lexicon\n",
    "# New words and values\n",
    "new_words = {\n",
    "    'yolo': 100,\n",
    "    'dd': 25,\n",
    "    'double down': 25,\n",
    "    'moon': 25,\n",
    "    'dh':20,\n",
    "    'diamond hands':20,\n",
    "    'hold': 20,\n",
    "\n",
    "    # Need to understand better the following ones\n",
    "    'bullish': 10,\n",
    "    'BTFD': 5,\n",
    "    'FD': 5,\n",
    "\n",
    "    'paper hands': -5,\n",
    "    'bagholder': -5,\n",
    "    'bearish':-10,\n",
    "\n",
    "    # usual journalist stock jargon\n",
    "    'crushes': 10,\n",
    "    'beats': 5,\n",
    "    'misses': -5,\n",
    "    'trouble': -10,\n",
    "    'falls': -100,\n",
    "}\n",
    "vader.lexicon.update(new_words)\n",
    "\n",
    "# scores = df_wsb['body'].astype(str).apply(vader.polarity_scores)\n",
    "scores = df_wsb['title'].apply(vader.polarity_scores)\n",
    "scores_df = pd.DataFrame.from_records(scores)\n",
    "scored_news =pd.concat([df_wsb['timestamp'],df_wsb['title'],df_wsb['body'], scores_df], axis=1)\n",
    "scored_news\n",
    "\n",
    "# scores = df_wsb['body'].apply(vader.polarity_scores)\n",
    "# scores_df = pd.DataFrame.from_records(scores)\n",
    "# scored_news = pd.concat([df_wsb['body'], scores_df], axis=1)\n",
    "# scored_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "#\n",
    "# model = Word2Vec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}